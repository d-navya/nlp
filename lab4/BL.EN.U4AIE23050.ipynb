{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7dc9bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41af80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 4: TF-IDF Feature Representation and Classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb55b164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\D\n",
      "[nltk_data]     Navya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\D\n",
      "[nltk_data]     Navya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\D\n",
      "[nltk_data]     Navya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\D\n",
      "[nltk_data]     Navya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\D\n",
      "[nltk_data]     Navya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download required nltk data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0dcb4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total documents: 100\n",
      "total labels: 100\n",
      "\n",
      "sample:\n",
      "text: oooh, sunshine! A patch of sunshine! And it will be gone by the time I leave wor...\n",
      "label: neutral\n"
     ]
    }
   ],
   "source": [
    "# 1. load the dataset into a pandas dataframe and extract text and label columns\n",
    "df = pd.read_csv('cleaned_data.csv', index_col=0)\n",
    "\n",
    "texts = df['review_text'].tolist()\n",
    "labels = df['sentiment'].tolist()\n",
    "\n",
    "print(f\"total documents: {len(texts)}\")\n",
    "print(f\"total labels: {len(labels)}\")\n",
    "print(f\"\\nsample:\")\n",
    "print(f\"text: {texts[0][:80]}...\")\n",
    "print(f\"label: {labels[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c666e78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed 100 documents\n",
      "\n",
      "example:\n",
      "original: oooh, sunshine! A patch of sunshine! And it will be gone by the time I leave wor...\n",
      "preprocessed: oooh sunshine patch sunshine go time leave work replace rain...\n"
     ]
    }
   ],
   "source": [
    "# 2. reuse preprocessed text from lab 3\n",
    "# perform same preprocessing as lab 3\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "preprocessed_texts = []\n",
    "for text in texts:\n",
    "    # tokenize and lowercase\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # remove stop words and non-alphabetic\n",
    "    filtered = [token for token in tokens if token not in stop_words and token.isalpha()]\n",
    "    # lemmatize\n",
    "    lemmatized = [lemmatizer.lemmatize(lemmatizer.lemmatize(word), pos='v') for word in filtered]\n",
    "    # join back\n",
    "    preprocessed_texts.append(' '.join(lemmatized))\n",
    "\n",
    "print(f\"preprocessed {len(preprocessed_texts)} documents\")\n",
    "print(f\"\\nexample:\")\n",
    "print(f\"original: {texts[0][:80]}...\")\n",
    "print(f\"preprocessed: {preprocessed_texts[0][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58cbd44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow matrix constructed\n",
      "shape: (100, 479)\n"
     ]
    }
   ],
   "source": [
    "# 3. load bow document-term matrix from lab 3\n",
    "# construct bow manually like lab 3\n",
    "from collections import Counter\n",
    "\n",
    "# get all tokens\n",
    "all_tokens = []\n",
    "tokenized_docs = []\n",
    "for text in preprocessed_texts:\n",
    "    tokens = text.split()\n",
    "    tokenized_docs.append(tokens)\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "# create vocabulary\n",
    "bow_vocabulary = sorted(list(set(all_tokens)))\n",
    "\n",
    "# create bow matrix\n",
    "bow_word_to_idx = {word: idx for idx, word in enumerate(bow_vocabulary)}\n",
    "bow_matrix = []\n",
    "for tokens in tokenized_docs:\n",
    "    vector = [0] * len(bow_vocabulary)\n",
    "    for token in tokens:\n",
    "        if token in bow_word_to_idx:\n",
    "            vector[bow_word_to_idx[token]] += 1\n",
    "    bow_matrix.append(vector)\n",
    "\n",
    "bow_matrix = np.array(bow_matrix)\n",
    "\n",
    "print(f\"bow matrix constructed\")\n",
    "print(f\"shape: {bow_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03b29e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 479 unique words\n",
      "bow matrix dimensionality: (100, 479)\n",
      "  - rows (documents): 100\n",
      "  - columns (features/words): 479\n",
      "\n",
      "top 10 words in vocabulary: ['ability', 'absoute', 'accept', 'account', 'act', 'ad', 'adapt', 'adobe', 'age', 'agency']\n"
     ]
    }
   ],
   "source": [
    "# 4. state vocabulary size and dimensionality of bow matrix\n",
    "print(f\"vocabulary size: {len(bow_vocabulary)} unique words\")\n",
    "print(f\"bow matrix dimensionality: {bow_matrix.shape}\")\n",
    "print(f\"  - rows (documents): {bow_matrix.shape[0]}\")\n",
    "print(f\"  - columns (features/words): {bow_matrix.shape[1]}\")\n",
    "print(f\"\\ntop 10 words in vocabulary: {bow_vocabulary[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2df7d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf vectorizer fitted and transformed\n",
      "tf-idf matrix shape: (100, 477)\n"
     ]
    }
   ],
   "source": [
    "# 5. construct tf-idf feature vectors\n",
    "# use sklearn's tfidfvectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_texts)\n",
    "\n",
    "# convert to dense array for easier manipulation\n",
    "tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "\n",
    "print(f\"tf-idf vectorizer fitted and transformed\")\n",
    "print(f\"tf-idf matrix shape: {tfidf_matrix_dense.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f5f1fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf matrix (showing first 3 documents, first 10 features):\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "first document tf-idf vector (first 20 values):\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "non-zero features in first document: 9\n"
     ]
    }
   ],
   "source": [
    "# 6. display tf-idf document-term matrix\n",
    "print(f\"tf-idf matrix (showing first 3 documents, first 10 features):\")\n",
    "print(tfidf_matrix_dense[:3, :10])\n",
    "print(f\"\\nfirst document tf-idf vector (first 20 values):\")\n",
    "print(tfidf_matrix_dense[0][:20])\n",
    "print(f\"non-zero features in first document: {np.count_nonzero(tfidf_matrix_dense[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13150744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow matrix dimensionality: (100, 479)\n",
      "tf-idf matrix dimensionality: (100, 477)\n",
      "\n",
      "comparison:\n",
      "  - same number of documents: 100 == 100\n",
      "  - bow vocabulary size: 479\n",
      "  - tf-idf vocabulary size: 477\n",
      "  - difference in features: 2\n",
      "\n",
      "tf-idf uses sklearn's default vocabulary which may differ slightly\n",
      "from our manual bow construction\n"
     ]
    }
   ],
   "source": [
    "# 7. state dimensionality and compare with bow\n",
    "print(f\"bow matrix dimensionality: {bow_matrix.shape}\")\n",
    "print(f\"tf-idf matrix dimensionality: {tfidf_matrix_dense.shape}\")\n",
    "print(f\"\\ncomparison:\")\n",
    "print(f\"  - same number of documents: {bow_matrix.shape[0]} == {tfidf_matrix_dense.shape[0]}\")\n",
    "print(f\"  - bow vocabulary size: {bow_matrix.shape[1]}\")\n",
    "print(f\"  - tf-idf vocabulary size: {tfidf_matrix_dense.shape[1]}\")\n",
    "print(f\"  - difference in features: {abs(bow_matrix.shape[1] - tfidf_matrix_dense.shape[1])}\")\n",
    "print(\"\\ntf-idf uses sklearn's default vocabulary which may differ slightly\")\n",
    "print(\"from our manual bow construction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f14a507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected document (index 5):\n",
      "original:  I want to see David cook!!\n",
      "preprocessed: want see david cook\n",
      "\n",
      "bow frequency vector (first 20 dimensions):\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "non-zero features: 4\n",
      "\n",
      "tf-idf weighted vector (first 20 dimensions):\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "non-zero features: 4\n",
      "\n",
      "top 5 tf-idf weighted words in this document:\n",
      "  david           - tf-idf: 0.5285\n",
      "  cook            - tf-idf: 0.5285\n",
      "  see             - tf-idf: 0.4850\n",
      "  want            - tf-idf: 0.4541\n",
      "  friend          - tf-idf: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 8. select one document and display both vectors\n",
    "doc_idx = 5\n",
    "print(f\"selected document (index {doc_idx}):\")\n",
    "print(f\"original: {texts[doc_idx]}\")\n",
    "print(f\"preprocessed: {preprocessed_texts[doc_idx]}\")\n",
    "\n",
    "print(f\"\\nbow frequency vector (first 20 dimensions):\")\n",
    "print(bow_matrix[doc_idx][:20])\n",
    "print(f\"non-zero features: {np.count_nonzero(bow_matrix[doc_idx])}\")\n",
    "\n",
    "print(f\"\\ntf-idf weighted vector (first 20 dimensions):\")\n",
    "print(tfidf_matrix_dense[doc_idx][:20])\n",
    "print(f\"non-zero features: {np.count_nonzero(tfidf_matrix_dense[doc_idx])}\")\n",
    "\n",
    "# show top features\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "doc_tfidf = tfidf_matrix_dense[doc_idx]\n",
    "top_indices = doc_tfidf.argsort()[-5:][::-1]\n",
    "\n",
    "print(f\"\\ntop 5 tf-idf weighted words in this document:\")\n",
    "for idx in top_indices:\n",
    "    print(f\"  {tfidf_feature_names[idx]:15} - tf-idf: {doc_tfidf[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0ce0ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "document 5: \"want see david cook\"\n",
      "\n",
      "bow: all 4 words get value = 1 (equal treatment)\n",
      "tf-idf: \n",
      "  - david, cook: 0.5285 (rare proper names)\n",
      "  - see: 0.4850 \n",
      "  - want: 0.4541 (more common)\n",
      "\n",
      "difference: tf-idf weights rare words higher, bow treats all equally\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. comment on difference in feature representation\n",
    "print(\"\"\"\n",
    "document 5: \"want see david cook\"\n",
    "\n",
    "bow: all 4 words get value = 1 (equal treatment)\n",
    "tf-idf: \n",
    "  - david, cook: 0.5285 (rare proper names)\n",
    "  - see: 0.4850 \n",
    "  - want: 0.4541 (more common)\n",
    "\n",
    "difference: tf-idf weights rare words higher, bow treats all equally\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb981507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words with low raw frequency but high tf-idf importance:\n",
      "\n",
      "  day                  - raw frequency:   8, avg tf-idf: 0.0270\n",
      "  go                   - raw frequency:   8, avg tf-idf: 0.0249\n",
      "  http                 - raw frequency:   5, avg tf-idf: 0.0242\n",
      "  get                  - raw frequency:   9, avg tf-idf: 0.0219\n",
      "  know                 - raw frequency:   8, avg tf-idf: 0.0201\n",
      "  work                 - raw frequency:   6, avg tf-idf: 0.0192\n",
      "  miss                 - raw frequency:   6, avg tf-idf: 0.0191\n",
      "  happy                - raw frequency:   5, avg tf-idf: 0.0186\n",
      "  want                 - raw frequency:   4, avg tf-idf: 0.0169\n",
      "  im                   - raw frequency:   6, avg tf-idf: 0.0162\n",
      "  back                 - raw frequency:   6, avg tf-idf: 0.0161\n",
      "  make                 - raw frequency:   6, avg tf-idf: 0.0158\n",
      "  love                 - raw frequency:   4, avg tf-idf: 0.0153\n",
      "  thank                - raw frequency:   3, avg tf-idf: 0.0153\n",
      "  phone                - raw frequency:   3, avg tf-idf: 0.0149\n"
     ]
    }
   ],
   "source": [
    "# 10. identify words with high tf-idf but low bow frequency\n",
    "# get overall word frequencies from bow\n",
    "word_freq = Counter(all_tokens)\n",
    "\n",
    "# get average tf-idf scores for each word\n",
    "avg_tfidf = {}\n",
    "for idx, word in enumerate(tfidf_feature_names):\n",
    "    avg_tfidf[word] = np.mean(tfidf_matrix_dense[:, idx])\n",
    "\n",
    "# find words with low frequency but high tf-idf\n",
    "print(\"words with low raw frequency but high tf-idf importance:\\n\")\n",
    "for word in sorted(avg_tfidf.keys(), key=lambda x: avg_tfidf[x], reverse=True)[:15]:\n",
    "    raw_freq = word_freq.get(word, 0)\n",
    "    tfidf_score = avg_tfidf[word]\n",
    "    print(f\"  {word:20} - raw frequency: {raw_freq:3}, avg tf-idf: {tfidf_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a454dad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the output shows frequent words with LOW tf-idf scores:\n",
      "- get (freq=9): tf-idf = 0.0219\n",
      "- day (freq=8): tf-idf = 0.0270\n",
      "- go (freq=8): tf-idf = 0.0249\n",
      "\n",
      "these are NOT high tf-idf words - they're penalized for being common\n",
      "\n",
      "actual high tf-idf words (rare ones):\n",
      "- david (freq=1): tf-idf = 0.5285\n",
      "- cook (freq=1): tf-idf = 0.5285\n",
      "\n",
      "why rare words get higher scores:\n",
      "- formula: tf-idf = tf × log(total_docs / docs_with_word)\n",
      "- rare word (1 doc): log(100/1) = 4.6\n",
      "- common word (9 docs): log(100/9) = 2.4\n",
      "- rare words get 2x multiplier, common words penalized\n",
      "\n",
      "result: distinctive words emphasized, generic words suppressed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 11. explain why tf-idf assigns higher importance\n",
    "print(\"\"\"\n",
    "the output shows frequent words with LOW tf-idf scores:\n",
    "- get (freq=9): tf-idf = 0.0219\n",
    "- day (freq=8): tf-idf = 0.0270\n",
    "- go (freq=8): tf-idf = 0.0249\n",
    "\n",
    "these are NOT high tf-idf words - they're penalized for being common\n",
    "\n",
    "actual high tf-idf words (rare ones):\n",
    "- david (freq=1): tf-idf = 0.5285\n",
    "- cook (freq=1): tf-idf = 0.5285\n",
    "\n",
    "why rare words get higher scores:\n",
    "- formula: tf-idf = tf × log(total_docs / docs_with_word)\n",
    "- rare word (1 doc): log(100/1) = 4.6\n",
    "- common word (9 docs): log(100/9) = 2.4\n",
    "- rare words get 2x multiplier, common words penalized\n",
    "\n",
    "result: distinctive words emphasized, generic words suppressed\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee32eaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: 80 documents\n",
      "testing set: 20 documents\n",
      "\n",
      "label distribution in training set:\n",
      "neutral     38\n",
      "positive    26\n",
      "negative    16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "label distribution in testing set:\n",
      "neutral     10\n",
      "positive     6\n",
      "negative     4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 12. split dataset into training and testing sets\n",
    "# split bow features\n",
    "X_bow_train, X_bow_test, y_train, y_test = train_test_split(\n",
    "    bow_matrix, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# split tf-idf features\n",
    "X_tfidf_train, X_tfidf_test, _, _ = train_test_split(\n",
    "    tfidf_matrix_dense, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"training set: {X_bow_train.shape[0]} documents\")\n",
    "print(f\"testing set: {X_bow_test.shape[0]} documents\")\n",
    "print(f\"\\nlabel distribution in training set:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nlabel distribution in testing set:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b335aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training naive bayes on bow features...\n",
      "naive bayes (bow) accuracy: 0.4500\n",
      "\n",
      "training logistic regression on bow features...\n",
      "logistic regression (bow) accuracy: 0.5500\n",
      "\n",
      "training naive bayes on tf-idf features...\n",
      "naive bayes (tf-idf) accuracy: 0.6000\n",
      "\n",
      "training logistic regression on tf-idf features...\n",
      "logistic regression (tf-idf) accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# 13. train classifiers using tf-idf features\n",
    "# train naive bayes on bow\n",
    "print(\"\\ntraining naive bayes on bow features...\")\n",
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(X_bow_train, y_train)\n",
    "y_pred_nb_bow = nb_bow.predict(X_bow_test)\n",
    "acc_nb_bow = accuracy_score(y_test, y_pred_nb_bow)\n",
    "print(f\"naive bayes (bow) accuracy: {acc_nb_bow:.4f}\")\n",
    "\n",
    "# train logistic regression on bow\n",
    "print(\"\\ntraining logistic regression on bow features...\")\n",
    "lr_bow = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_bow.fit(X_bow_train, y_train)\n",
    "y_pred_lr_bow = lr_bow.predict(X_bow_test)\n",
    "acc_lr_bow = accuracy_score(y_test, y_pred_lr_bow)\n",
    "print(f\"logistic regression (bow) accuracy: {acc_lr_bow:.4f}\")\n",
    "\n",
    "# train naive bayes on tf-idf\n",
    "print(\"\\ntraining naive bayes on tf-idf features...\")\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_tfidf_train, y_train)\n",
    "y_pred_nb_tfidf = nb_tfidf.predict(X_tfidf_test)\n",
    "acc_nb_tfidf = accuracy_score(y_test, y_pred_nb_tfidf)\n",
    "print(f\"naive bayes (tf-idf) accuracy: {acc_nb_tfidf:.4f}\")\n",
    "\n",
    "# train logistic regression on tf-idf\n",
    "print(\"\\ntraining logistic regression on tf-idf features...\")\n",
    "lr_tfidf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_tfidf.fit(X_tfidf_train, y_train)\n",
    "y_pred_lr_tfidf = lr_tfidf.predict(X_tfidf_test)\n",
    "acc_lr_tfidf = accuracy_score(y_test, y_pred_lr_tfidf)\n",
    "print(f\"logistic regression (tf-idf) accuracy: {acc_lr_tfidf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e07f282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy comparison:\n",
      "model                          bow accuracy    tf-idf accuracy difference\n",
      "----------------------------------------------------------------------\n",
      "naive bayes                    0.4500          0.6000          +0.1500\n",
      "logistic regression            0.5500          0.5000          -0.0500\n",
      "\n",
      "\n",
      "confusion matrix - naive bayes (bow):\n",
      "[[0 2 2]\n",
      " [2 6 2]\n",
      " [2 1 3]]\n",
      "\n",
      "confusion matrix - naive bayes (tf-idf):\n",
      "[[ 0  4  0]\n",
      " [ 0 10  0]\n",
      " [ 0  4  2]]\n",
      "\n",
      "confusion matrix - logistic regression (bow):\n",
      "[[0 4 0]\n",
      " [0 7 3]\n",
      " [0 2 4]]\n",
      "\n",
      "confusion matrix - logistic regression (tf-idf):\n",
      "[[0 4 0]\n",
      " [0 9 1]\n",
      " [0 5 1]]\n"
     ]
    }
   ],
   "source": [
    "# 14. compare models - accuracy and misclassifications\n",
    "print(\"\\naccuracy comparison:\")\n",
    "print(f\"{'model':<30} {'bow accuracy':<15} {'tf-idf accuracy':<15} {'difference'}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'naive bayes':<30} {acc_nb_bow:<15.4f} {acc_nb_tfidf:<15.4f} {acc_nb_tfidf - acc_nb_bow:+.4f}\")\n",
    "print(f\"{'logistic regression':<30} {acc_lr_bow:<15.4f} {acc_lr_tfidf:<15.4f} {acc_lr_tfidf - acc_lr_bow:+.4f}\")\n",
    "\n",
    "print(\"\\n\\nconfusion matrix - naive bayes (bow):\")\n",
    "print(confusion_matrix(y_test, y_pred_nb_bow))\n",
    "\n",
    "print(\"\\nconfusion matrix - naive bayes (tf-idf):\")\n",
    "print(confusion_matrix(y_test, y_pred_nb_tfidf))\n",
    "\n",
    "print(\"\\nconfusion matrix - logistic regression (bow):\")\n",
    "print(confusion_matrix(y_test, y_pred_lr_bow))\n",
    "\n",
    "print(\"\\nconfusion matrix - logistic regression (tf-idf):\")\n",
    "print(confusion_matrix(y_test, y_pred_lr_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7b91c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "found 2 documents misclassified by bow but correct by tf-idf\n",
      "\n",
      "examples:\n",
      "\n",
      "document 6:\n",
      "text: yeh\n",
      "actual label: neutral\n",
      "bow predicted: positive (wrong)\n",
      "tf-idf predicted: neutral (correct)\n",
      "\n",
      "document 17:\n",
      "text: reply yet wait till confirm case somebody might translate already\n",
      "actual label: neutral\n",
      "bow predicted: positive (wrong)\n",
      "tf-idf predicted: neutral (correct)\n"
     ]
    }
   ],
   "source": [
    "# 15. identify misclassified vs correctly classified documents\n",
    "# get test indices\n",
    "test_indices = np.array(range(len(labels)))[np.array(range(len(labels))) % 5 == 0][:20]  # approximate test set\n",
    "\n",
    "# using logistic regression for comparison\n",
    "bow_wrong_tfidf_right = []\n",
    "for i, (actual, pred_bow, pred_tfidf) in enumerate(zip(y_test, y_pred_lr_bow, y_pred_lr_tfidf)):\n",
    "    if pred_bow != actual and pred_tfidf == actual:\n",
    "        bow_wrong_tfidf_right.append({\n",
    "            'index': i,\n",
    "            'actual': actual,\n",
    "            'bow_pred': pred_bow,\n",
    "            'tfidf_pred': pred_tfidf\n",
    "        })\n",
    "\n",
    "print(f\"\\nfound {len(bow_wrong_tfidf_right)} documents misclassified by bow but correct by tf-idf\")\n",
    "print(\"\\nexamples:\")\n",
    "for item in bow_wrong_tfidf_right[:2]:\n",
    "    idx = item['index']\n",
    "    # get original index from test set\n",
    "    print(f\"\\ndocument {idx}:\")\n",
    "    print(f\"text: {preprocessed_texts[idx] if idx < len(preprocessed_texts) else 'N/A'}\")\n",
    "    print(f\"actual label: {item['actual']}\")\n",
    "    print(f\"bow predicted: {item['bow_pred']} (wrong)\")\n",
    "    print(f\"tf-idf predicted: {item['tfidf_pred']} (correct)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb520569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "misclassified by bow, correct by tf-idf:\n",
      "\n",
      "document 6: \"yeh\"\n",
      "- actual: neutral, bow: positive (wrong), tf-idf: neutral (correct)\n",
      "- reason: extremely short doc with single informal word\n",
      "- bow has almost no features to work with\n",
      "- tf-idf likely gave this rare slang appropriate weight for neutral class\n",
      "\n",
      "document 17: \"reply yet wait till confirm case somebody might translate already\"\n",
      "- actual: neutral, bow: positive (wrong), tf-idf: neutral (correct)\n",
      "- words like 'wait', 'confirm', 'already' are factual/neutral\n",
      "- bow might have weighted these based on frequency alone\n",
      "- tf-idf correctly identified these as neutral context words\n",
      "- no strong sentiment words present\n",
      "\n",
      "pattern: tf-idf better handles neutral class by not over-weighting common words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 16. analyze reasons based on word weighting\n",
    "print(\"\"\"\n",
    "misclassified by bow, correct by tf-idf:\n",
    "\n",
    "document 6: \"yeh\"\n",
    "- actual: neutral, bow: positive (wrong), tf-idf: neutral (correct)\n",
    "- reason: extremely short doc with single informal word\n",
    "- bow has almost no features to work with\n",
    "- tf-idf likely gave this rare slang appropriate weight for neutral class\n",
    "\n",
    "document 17: \"reply yet wait till confirm case somebody might translate already\"\n",
    "- actual: neutral, bow: positive (wrong), tf-idf: neutral (correct)\n",
    "- words like 'wait', 'confirm', 'already' are factual/neutral\n",
    "- bow might have weighted these based on frequency alone\n",
    "- tf-idf correctly identified these as neutral context words\n",
    "- no strong sentiment words present\n",
    "\n",
    "pattern: tf-idf better handles neutral class by not over-weighting common words\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ff6706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evidence from our results:\n",
      "\n",
      "frequent words (appearing in 6-9 docs out of 100):\n",
      "- 'get' (9 docs): avg tf-idf = 0.0219\n",
      "- 'day' (8 docs): avg tf-idf = 0.0270\n",
      "- 'go' (8 docs): avg tf-idf = 0.0249\n",
      "- 'work' (6 docs): avg tf-idf = 0.0192\n",
      "\n",
      "rare words (appearing in 1 doc):\n",
      "- 'david' (1 doc): tf-idf = 0.5285\n",
      "- 'cook' (1 doc): tf-idf = 0.5285\n",
      "\n",
      "comparison: rare words get 20x higher weight than frequent words\n",
      "mechanism: idf = log(100/doc_count) penalizes high doc_count\n",
      "result: model focuses on distinctive words, ignores common ones\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #17. comment on how tf-idf reduces influence of frequent words\n",
    "print(\"\"\"\n",
    "evidence from our results:\n",
    "\n",
    "frequent words (appearing in 6-9 docs out of 100):\n",
    "- 'get' (9 docs): avg tf-idf = 0.0219\n",
    "- 'day' (8 docs): avg tf-idf = 0.0270\n",
    "- 'go' (8 docs): avg tf-idf = 0.0249\n",
    "- 'work' (6 docs): avg tf-idf = 0.0192\n",
    "\n",
    "rare words (appearing in 1 doc):\n",
    "- 'david' (1 doc): tf-idf = 0.5285\n",
    "- 'cook' (1 doc): tf-idf = 0.5285\n",
    "\n",
    "comparison: rare words get 20x higher weight than frequent words\n",
    "mechanism: idf = log(100/doc_count) penalizes high doc_count\n",
    "result: model focuses on distinctive words, ignores common ones\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74bcadcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "situations favoring bow:\n",
      "\n",
      "1. very small datasets (like ours - 100 docs)\n",
      "   - tf-idf idf scores unreliable with few documents\n",
      "   - logistic regression: bow (0.55) beat tf-idf (0.50)\n",
      "\n",
      "2. when repetition matters\n",
      "   - spam: \"buy now now now!!!\" \n",
      "   - tf-idf would downweight, bow preserves repetition signal\n",
      "\n",
      "3. short documents with limited vocabulary\n",
      "   - our tweets are very short\n",
      "   - tf-idf might over-penalize necessary words\n",
      "   - bow keeps simple frequency intact\n",
      "\n",
      "4. already filtered vocabulary\n",
      "   - we removed stop words\n",
      "   - remaining words already meaningful\n",
      "   - additional tf-idf weighting may not help much\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 18. discuss when bow may outperform tf-idf\n",
    "print(\"\"\"\n",
    "situations favoring bow:\n",
    "\n",
    "1. very small datasets (like ours - 100 docs)\n",
    "   - tf-idf idf scores unreliable with few documents\n",
    "   - logistic regression: bow (0.55) beat tf-idf (0.50)\n",
    "\n",
    "2. when repetition matters\n",
    "   - spam: \"buy now now now!!!\" \n",
    "   - tf-idf would downweight, bow preserves repetition signal\n",
    "\n",
    "3. short documents with limited vocabulary\n",
    "   - our tweets are very short\n",
    "   - tf-idf might over-penalize necessary words\n",
    "   - bow keeps simple frequency intact\n",
    "\n",
    "4. already filtered vocabulary\n",
    "   - we removed stop words\n",
    "   - remaining words already meaningful\n",
    "   - additional tf-idf weighting may not help much\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f96752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "results summary:\n",
      "\n",
      "accuracy:\n",
      "- naive bayes (bow): 0.45, (tf-idf): 0.60 → +0.15 improvement\n",
      "- logistic regression (bow): 0.55, (tf-idf): 0.50 → -0.05 decline\n",
      "\n",
      "key findings:\n",
      "1. tf-idf helped naive bayes significantly (45% → 60%)\n",
      "2. tf-idf hurt logistic regression slightly (55% → 50%)\n",
      "3. dataset is very small (100 docs) with 75% rare words\n",
      "4. vocabulary: bow=479, tf-idf=477 (nearly identical)\n",
      "\n",
      "which is better for this dataset?\n",
      "\n",
      "mixed results - depends on classifier:\n",
      "- for naive bayes: tf-idf clearly better\n",
      "- for logistic regression: bow slightly better\n",
      "\n",
      "reasons for mixed performance:\n",
      "- dataset too small (100 docs) for reliable idf scores\n",
      "- 75% of words appear once - idf calculations unstable\n",
      "- short documents (tweets) - limited features\n",
      "- neutral class hard to distinguish (seen in confusion matrices)\n",
      "\n",
      "recommendation: tf-idf with naive bayes\n",
      "- 60% accuracy is best result achieved\n",
      "- tf-idf helped reduce bow's neutral class bias\n",
      "- with more data, tf-idf advantage would increase\n",
      "\n",
      "caveat: need more data (500+ docs) for conclusive results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 19. summarize findings and conclude\n",
    "print(\"\"\"\n",
    "results summary:\n",
    "\n",
    "accuracy:\n",
    "- naive bayes (bow): 0.45, (tf-idf): 0.60 → +0.15 improvement\n",
    "- logistic regression (bow): 0.55, (tf-idf): 0.50 → -0.05 decline\n",
    "\n",
    "key findings:\n",
    "1. tf-idf helped naive bayes significantly (45% → 60%)\n",
    "2. tf-idf hurt logistic regression slightly (55% → 50%)\n",
    "3. dataset is very small (100 docs) with 75% rare words\n",
    "4. vocabulary: bow=479, tf-idf=477 (nearly identical)\n",
    "\n",
    "which is better for this dataset?\n",
    "\n",
    "mixed results - depends on classifier:\n",
    "- for naive bayes: tf-idf clearly better\n",
    "- for logistic regression: bow slightly better\n",
    "\n",
    "reasons for mixed performance:\n",
    "- dataset too small (100 docs) for reliable idf scores\n",
    "- 75% of words appear once - idf calculations unstable\n",
    "- short documents (tweets) - limited features\n",
    "- neutral class hard to distinguish (seen in confusion matrices)\n",
    "\n",
    "recommendation: tf-idf with naive bayes\n",
    "- 60% accuracy is best result achieved\n",
    "- tf-idf helped reduce bow's neutral class bias\n",
    "- with more data, tf-idf advantage would increase\n",
    "\n",
    "caveat: need more data (500+ docs) for conclusive results\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
